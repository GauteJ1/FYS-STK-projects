Neural networks is the primary type of models used in complex machine learning problems, as they are extremely agile and can perform well in a wide range of scenarios, including both regression and classification tasks.
They do however require large amounts of data to be trained and it is hard to interpret how they make their predictions.
Classic models as linear and logistic regression are easier to interpret and simpler to fit to the data.
In this paper we compare the performance of linear regression, with both ordinary least squares and ridge, to neural networks with a range of architectures and activation functions, on the noisy Franke data set \cite{frank}, where we reuse our previous implementations of linear regression models \cite{project1}.
Furthermore we implement logistic regression, and compare its performance with neural networks on a classification task, based on the Wisconsin breast cancer data set \cite{breast_cancer_wisconsin}.

We find that our best neural networks perform better than linear regression at predicting the Franke data, however we emphasize the fact that neural networks are computationally heavier and less interpretable than the linear regression models.
Our best neural network model for this data set has \gaute{n} hidden layers with \gaute{...} nodes, trained using \gaute{...} with learning rate $\eta =$ \gaute{...}, achieving an MSE of \gaute{...}, while our best linear regression model had an MSE of $0.0987$.

\gaute{for the classifcation case ...}