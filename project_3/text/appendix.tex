\section{Appendices}
\subsection{Source code}

The code used for this project is available at \url{https://github.com/GauteJ1/FYS-STK-projects}. Instructions for running the code are located in \texttt{project\_3/README.md}.
All plots and results in this paper are easily reproducible in the Jupyter notebook files in this repository, by following the instructions mentioned above.

\subsection{Derivation of analytical solution}\label{appendixB}
%\mia{In this section we will be flexing our mathematical muscles by deriving the analytical solution of the diffusion equation.}
We want to solve the following equation (Note that this is Eq. \ref{eq:diffu} with $L=1$):
\begin{align}\label{ana:equation}
\frac{\partial^2 u(x,t)}{\partial x^2}  &=\frac{\partial u(x,t)}{\partial t}, \ t>0, \ x\in [0, 1] \\
\label{ana:init}
u(x, 0) &= \sin(\pi x), \quad 0 < x < 1 \\
\begin{split}
\label{ana:bound}
    u(0,t) &= 0, \quad t\geq 0 \\
    u(1,t) &= 0, \quad t\geq 0
\end{split}
\end{align}

We start by making an assumption, ansatz, that the solution $u(x,t)$ can be written on the form
\begin{equation}\label{ana:ansatz}
u(x,t) = X(x)T(t)
\end{equation}
for some functions $X,\ T$ which only depend on $x,\ t$ respectively.
Inserting equation \ref{ana:ansatz} into equation \ref{ana:equation}, we get

\begin{align}
    X''(x)T(t) &= X(x) T'(x) \nonumber \\
    \frac{X''(x)}{X(x)} &= \frac{T'(t)}{T(t)} \label{ana:sepa}
\end{align}

As the left hand side of equation \ref{ana:sepa} only depends on $x$, while the right side only depends on $t$, they both have to equal some constant, say $-\lambda$. The minus sign is included for convenience, see \textcite[p. 90]{tveitoPDE}.

\begin{equation}
     \frac{X''(x)}{X(x)} = -\lambda = \frac{T'(t)}{T(t)} \label{ana:seplmbda}
\end{equation}

We start by solving the left side of equation \ref{ana:seplmbda}.

\begin{equation*}
    X''(x) = -\lambda X(x)
\end{equation*}
From equations \ref{ana:bound} and \ref{ana:sepa}, we get the boundary conditions 
$X(0) = X(1) = 0$.
Setting $\lambda = (k\pi)^2$, we see that this has solution
\begin{equation*}
    X(x) = \sin(k \pi x) , \quad k \in \mathbb{N}
\end{equation*}

While we in the general case would have to use linear combinations of a family of solutions $X_k(x) = \sin(k \pi x)$ for $k \in \mathbb{N}$, however, due to our simple initial condition (Eq. \ref{ana:init}), we see that $k=1$ is the only valid solution. 
For more details on the general case, see \textcite[p. 92]{tveitoPDE}.
\begin{equation}\label{ana:xsol}
        X(x) = \sin(\pi x)
\end{equation}

Now, using $\lambda = (k\pi)^2 = \pi^2$, we can easily solve the left side of equation \ref{ana:seplmbda}.
The equation now becomes the following:
\begin{equation*}
    T'(t) = -\lambda T(t) = -\pi^2 T(t)
\end{equation*}
This is easy to solve by integrating both sides of the equation.
\begin{equation}\label{ana:tsol}
    T(t) = e^{-\pi^2 t} + c
\end{equation}
The $c$ in equation \ref{ana:tsol} is a constant.
Due to the initial condition of the problem (Eq. \ref{ana:init}) and our solution for $X(x)$ (Eq. \ref{ana:xsol}), we must have $T(0) = 1$, and hence $c = 0$.
Combining equations \ref{ana:xsol} and \ref{ana:tsol} (by inserting their values into Eq. \ref{ana:ansatz}), we get the final solution.
\begin{equation}
    u(x,t) = \sin(\pi x) e^{-\pi^2 t}
\end{equation}

To conclude this appendix, we check our solution by inserting it into equations \ref{ana:equation}, \ref{ana:init} and \ref{ana:bound}.

For equation \ref{ana:equation}, we calculate the left and right sides separately.
\begin{align}
    \label{ana:xcheck}
    \frac{\partial^2 u(x,t)}{\partial x^2} &= \left(-\pi^2 \sin(\pi x)\right) e^{-\pi^2 t} \\
    \label{ana:tcheck}
    \frac{\partial u(x,t)}{\partial t} &=  \sin(\pi x) \left(-\pi^2 e^{-\pi^2 t}\right)
\end{align}
We see that the left hand side (Eq. \ref{ana:xcheck}) and the right hand side (Eq. \ref{ana:tcheck}) are equivalent.
Furthermore, the initial conditions (Eq. \ref{ana:init}) and boundary conditions (Eq. \ref{ana:bound}) are checked below.

\begin{align*}
    u(x, 0) &= \sin(\pi x) e^{-\pi^2 0} = \sin(\pi x) \\
    u(0, t) &= \sin(0)e^{-\pi^2 t} = 0 \\
    u(1, t) &= \sin(\pi)e^{-\pi^2 t} = 0
\end{align*}

This concludes the derivation of the analytic solution.
\clearpage

\subsection{Derivation of finite difference schemes} \label{appendixC}
This section derives the approximations used for the finite differences scheme as stated in Eq. \eqref{eq:fd_dt} and Eq. \eqref{eq:fd_dx2}, and shows the order of their error.

\begin{equation} \label{taylor_t}
    u_j^{n+1} = u(x_j, t_n + \Delta t)
    = u_j^n + \Delta t \frac{\partial}{\partial t}(x_j, t_n) + \mathcal{O}(\Delta t^2)
\end{equation}

For Eq. \eqref{eq:fd_dt}, we need the Taylor expansion of $u_j^{n+1}$ around the point $u_j^n$, which is stated in Eq. \eqref{taylor_t}.
From this, we get:

\begin{equation}
    \frac{u_j^{n+1} - u_j^n}{\Delta t} = \frac{\partial}{\partial t}(x_j, t_n) + \mathcal{O}(\Delta t)
\end{equation}

Hence, we have shown that the approximation in \eqref{eq:fd_dt}is correct, and has an error of order $\mathcal{O}(\Delta x)$.

We now consider the approximation for the second derivative on $x$, where we will need the following Taylor expansions.

\begin{align}
\begin{split}
    u_{j+1}^n &= u_j^n + \Delta x \frac{\partial}{\partial x}(x_j, t_n) 
    + \frac{\Delta x^2}{2} \frac{\partial^2}{\partial x^2}(x_j, t_n) 
    \\ &+ \frac{\Delta x^3}{6} \frac{\partial^3}{\partial x^3}(x_j, t_n)
    + \mathcal{O}(\Delta x^4)
\end{split} \\
\begin{split}
    u_{j-1}^n &= u_j^n - \Delta x \frac{\partial}{\partial x}(x_j, t_n)
    + \frac{\Delta x^2}{2} \frac{\partial^2}{\partial x^2}(x_j, t_n) 
    \\ &- \frac{\Delta x^3}{6} \frac{\partial^3}{\partial x^3}(x_j, t_n)
    + \mathcal{O}(\Delta x^4)
\end{split}
\end{align}
Inputting this in the right side of Eq. \eqref{eq:fd_dx2} and removing opposite terms in the two expression, give:
\begin{equation}
    \frac{u_{j+1}^n - 2u_j^n + u_{j-1}^n}{\Delta x^2} =
    \frac{\partial^2}{\partial x^2}(x_j, t_n) + \mathcal{O}(\Delta x^2)
\end{equation}
This proves the approximation, and shows that the error is of order $\mathcal{O}(\Delta x^2)$.
\newpage
\subsection{Derivation of stability requirement} \label{appendixD}

This section derives the stability requirement for the finite different scheme in Eq. \ref{eq:diff_scheme}, as stated in Eq. \ref{eq:stability}.

Inspired by the initial condition often being some general wave, we make an ansatz about a general solution form of the equation.

\begin{equation}
    \label{eq:stability_ansatz}
    u_j^n = A^n e^{i k x_j}
\end{equation}

Here, $e^{i k x_j}$ is a general wave, and $A$ is the amplification factor in the time step.
By inserting Eq. \ref{eq:stability_ansatz} in Eq. \ref{eq:diff_scheme}, we get:

\begin{equation}
    \frac{A^{n+1}e^{i k x_j} - A^n e^{i k x_{j+1}}}{\Delta t} = A^n \frac{e^{i k x_j} - 2e^{i k x_j} + e^{i k x_{j-1}}}{\Delta x^2} 
\end{equation}
Using $x_{j+1} = x_j +\Delta x$ and $x_{j-1} = x_j -\Delta x$, in addition to the trigonometric identity $e^{k\Delta x} + e^{-k \Delta x} = 2\cos (k\Delta x)$, together with some algebra, we get:
\begin{equation}
    A = \frac{\Delta t}{\Delta x^2}(2 \cos(k \Delta x) - 2) + 1    
\end{equation}
For stability we need $|A| \leq 1$.
This leads to:
\begin{equation}\label{d4}
    -2 \leq \frac{\Delta t}{\Delta x^2}(2 \cos(k \Delta x) - 2) \leq 0
\end{equation}
Since $\Delta t > 0$, and $\cos(k \Delta x) \leq 1$, the right inequality in \ref{d4} always holds.
Furthermore, since $\cos(k \Delta x) \geq -1$, we have at worst:
\begin{align}
\begin{split}
    \frac{\Delta t}{\Delta x^2}(-2 - 2) &\geq -2 \\
    -4\frac{\Delta t}{\Delta x^2} &\geq -2 \\
    \frac{\Delta t}{\Delta x^2} &\leq \frac{1}{2}
\end{split}
\end{align}
Hence this is the stability requirement for the scheme in Eq. \ref{eq:diff_scheme}.